{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Steps\n",
    "\n",
    "* Build vocab files for user and item, textline format: field  value  idx\n",
    "* Filter multicore rating data\n",
    "* Holdout train-val-test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "\n",
    "DATA_ROOT = \"~/datasets/\"\n",
    "PROCESSED_DATA_ROOT = \"~/workspace/experiments/\"\n",
    "data_path = DATA_ROOT + \"amazon_rating_only/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data file name, main_cat field in meta\n",
    "domain = [\"Movies_and_TV\", \"Movies_and_TV\", 40, 10]\n",
    "\n",
    "target_path = PROCESSED_DATA_ROOT + \"amz_\" + domain[0] + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>Response</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0871167042</td>\n",
       "      <td>A2IC3NZN488KWK</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1399161600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0871167042</td>\n",
       "      <td>A3OT9BYASFGU2X</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1398470400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0871167042</td>\n",
       "      <td>A28GK1G2KDXHRP</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1397692800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemID          UserID  Response   Timestamp\n",
       "0  0871167042  A2IC3NZN488KWK       5.0  1399161600\n",
       "1  0871167042  A3OT9BYASFGU2X       4.0  1398470400\n",
       "2  0871167042  A28GK1G2KDXHRP       5.0  1397692800"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_table(data_path + domain[0] + \".csv\", sep=\",\", names = [\"ItemID\", \"UserID\", \"Response\", \"Timestamp\"])\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#user: 12483678\n",
      "#item: 2681297\n",
      "sparsity: 0.9999990352633114\n"
     ]
    }
   ],
   "source": [
    "n_user, n_item = len(df.UserID.unique()), len(df.ItemID.unique())\n",
    "print(f\"#user: {n_user}\")\n",
    "print(f\"#item: {n_item}\")\n",
    "print(f\"sparsity: {1.0 - len(df) / (n_user * n_item)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-core is set to [5,100]\n",
      "Filtering (25,5)-core data\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32292099/32292099 [00:55<00:00, 578194.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 30237115\n",
      "Iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2054984/2054984 [00:04<00:00, 459340.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 942823\n",
      "Iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1112161/1112161 [00:02<00:00, 509268.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 427996\n",
      "Iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 684165/684165 [00:01<00:00, 475807.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 152870\n",
      "Iteration 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 531295/531295 [00:00<00:00, 604135.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 84459\n",
      "Iteration 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 446836/446836 [00:00<00:00, 512922.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 50486\n",
      "Iteration 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 396350/396350 [00:00<00:00, 756167.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 33237\n",
      "Iteration 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363113/363113 [00:00<00:00, 811367.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 23617\n",
      "Iteration 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 339496/339496 [00:00<00:00, 787554.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 18529\n",
      "Iteration 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 320967/320967 [00:00<00:00, 786311.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 13719\n",
      "Iteration 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307248/307248 [00:00<00:00, 707826.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 10345\n",
      "Iteration 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 296903/296903 [00:00<00:00, 812444.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 8631\n",
      "Iteration 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 288272/288272 [00:00<00:00, 720921.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 8155\n",
      "Iteration 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280117/280117 [00:00<00:00, 751718.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 7663\n",
      "Iteration 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272454/272454 [00:00<00:00, 814353.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 5809\n",
      "Iteration 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 266645/266645 [00:00<00:00, 835169.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 5201\n",
      "Iteration 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 261444/261444 [00:00<00:00, 733864.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 4456\n",
      "Iteration 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256988/256988 [00:00<00:00, 677125.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 4096\n",
      "Iteration 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 252892/252892 [00:00<00:00, 818093.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 3582\n",
      "Iteration 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249310/249310 [00:00<00:00, 874612.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 2639\n",
      "Iteration 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246671/246671 [00:00<00:00, 806263.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 2126\n",
      "Iteration 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 244545/244545 [00:00<00:00, 873063.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 2108\n",
      "Iteration 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242437/242437 [00:00<00:00, 901445.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 1582\n",
      "Iteration 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240855/240855 [00:00<00:00, 923760.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 1326\n",
      "Iteration 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239529/239529 [00:00<00:00, 938182.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 688\n",
      "Iteration 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238841/238841 [00:00<00:00, 842240.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 376\n",
      "Iteration 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238465/238465 [00:00<00:00, 824794.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 234\n",
      "Iteration 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238231/238231 [00:00<00:00, 968009.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 131\n",
      "Iteration 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238100/238100 [00:00<00:00, 826319.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 98\n",
      "Iteration 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238002/238002 [00:00<00:00, 783367.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 29\n",
      "Iteration 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237973/237973 [00:00<00:00, 929987.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 10\n",
      "Iteration 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237963/237963 [00:00<00:00, 893171.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 0\n",
      "Size change: 32292099 --> 237963\n"
     ]
    }
   ],
   "source": [
    "from data.preprocess import run_multicore, run_multicore_asymetric\n",
    "# multicore_data = run_multicore(df[[\"UserID\", \"ItemID\", \"Response\", \"Timestamp\"]], n_core = domain[2])\n",
    "multicore_data = run_multicore_asymetric(df[[\"UserID\", \"ItemID\", \"Response\", \"Timestamp\"]], n_core_user = domain[2], n_core_item = domain[3])\n",
    "# multicore_data = run_multicore_asymetric(multicore_data, n_core_user = 40, n_core_item = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#user: 7076\n",
      "#item: 3354\n",
      "#record: 237963\n",
      "sparsity: 0.989973287719025\n"
     ]
    }
   ],
   "source": [
    "n_user, n_item = len(multicore_data.UserID.unique()), len(multicore_data.ItemID.unique())\n",
    "print(f\"#user: {n_user}\")\n",
    "print(f\"#item: {n_item}\")\n",
    "print(f\"#record: {len(multicore_data)}\")\n",
    "print(f\"sparsity: {1.0 - len(multicore_data) / (n_user * n_item)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3354\n"
     ]
    }
   ],
   "source": [
    "items = {iid: False for iid in multicore_data['ItemID'].unique()}\n",
    "print(len(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2683667it [00:04, 561166.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item meta info of items in data set:\n",
      "Found: 3354\n",
      "Missing: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# pd.read_csv(data_path + \"meta/filtered_meta.csv\", sep = '\\t', nrows = 3)\n",
    "item_meta = {}\n",
    "with open(data_path + \"meta/filtered_meta.csv\", 'r') as fin:\n",
    "    fin.readline()\n",
    "    for i,line in tqdm(enumerate(fin)):\n",
    "        meta_info = line.strip().split(\"\\t\")\n",
    "        item_id = meta_info[0]\n",
    "        if item_id in items:\n",
    "            item_meta[item_id] = meta_info\n",
    "            del items[item_id]\n",
    "            if len(items) == 0:\n",
    "                break\n",
    "print(\"Item meta info of items in data set:\")\n",
    "print(f\"Found: {len(item_meta)}\")\n",
    "print(f\"Missing: {len(items)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-core is set to [5,100]\n",
      "Filtering (25,5)-core data\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237963/237963 [00:00<00:00, 837305.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 0\n",
      "Size change: 237963 --> 237963\n"
     ]
    }
   ],
   "source": [
    "selected_rows = [True] * len(multicore_data)\n",
    "for i,iid in enumerate(multicore_data[\"ItemID\"]):\n",
    "    if iid in items:\n",
    "        selected_rows[i] = False\n",
    "multicore_data = multicore_data[selected_rows]\n",
    "multicore_data = run_multicore_asymetric(multicore_data, domain[2], domain[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#user: 7076\n",
      "#item: 3354\n",
      "#record: 237963\n",
      "sparsity: 0.989973287719025\n"
     ]
    }
   ],
   "source": [
    "n_user, n_item = len(multicore_data.UserID.unique()), len(multicore_data.ItemID.unique())\n",
    "print(f\"#user: {n_user}\")\n",
    "print(f\"#item: {n_item}\")\n",
    "print(f\"#record: {len(multicore_data)}\")\n",
    "print(f\"sparsity: {1.0 - len(multicore_data) / (n_user * n_item)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "multicore_data = multicore_data.sort_values(by=['UserID','Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build user history\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "237963it [00:00, 491040.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout user histories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7076/7076 [00:00<00:00, 8082.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move unseen ItemID from val to train\n",
      "0/20660, finish in 626060009.0s.   \r",
      "Moving user data\n",
      "Before moving: Target DataFrame: 196643, Source Data Frame: 20660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [00:00<00:00, 3320.19it/s]\n",
      "100%|██████████| 6995/6995 [00:01<00:00, 4755.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#user moved: 81\n",
      "After moving: Target DataFrame: 197028, Source Data Frame: 20275\n",
      "Move unseen ItemID from test to train, this may also move users in val to train\n",
      "0/20660, finish in 406372547.1s.   \r",
      "Val --> Train\n",
      "Moving user data\n",
      "Before moving: Target DataFrame: 197028, Source Data Frame: 20275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 181/181 [00:00<00:00, 6589.67it/s]\n",
      "100%|██████████| 6846/6846 [00:01<00:00, 6015.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#user moved: 181\n",
      "After moving: Target DataFrame: 197550, Source Data Frame: 19753\n",
      "Test --> Train\n",
      "Moving user data\n",
      "Before moving: Target DataFrame: 197550, Source Data Frame: 20660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 181/181 [00:00<00:00, 4608.15it/s]\n",
      "100%|██████████| 6895/6895 [00:01<00:00, 4793.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#user moved: 181\n",
      "After moving: Target DataFrame: 198275, Source Data Frame: 19935\n"
     ]
    }
   ],
   "source": [
    "from utils import set_random_seed\n",
    "set_random_seed(9)\n",
    "from data.preprocess import holdout_data_sequential, recheck_exist\n",
    "trainset, valset, testset = holdout_data_sequential(multicore_data, holdout_type = \"warm\", ratio = [0.8,0.1,0.1])\n",
    "trainset = trainset.reset_index(drop = True)\n",
    "valset = valset.reset_index(drop = True)\n",
    "testset = testset.reset_index(drop = True)\n",
    "# recheck if there is any unseen item in val or test, if there is move corresponding user history into train\n",
    "trainset, valset, testset = recheck_exist(trainset, valset, testset, field_name = \"ItemID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7076, 6846, 6895)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset[\"UserID\"].unique()), len(valset[\"UserID\"].unique()), len(testset[\"UserID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3354, 1323, 1866)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset[\"ItemID\"].unique()), len(valset[\"ItemID\"].unique()), len(testset[\"ItemID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198275, 19753, 19935)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset), len(valset), len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "from utils import setup_path\n",
    "save_path = target_path + \"tsv_data/\"\n",
    "setup_path(save_path, is_dir = True)\n",
    "trainset.to_csv(save_path + \"train.tsv\", sep = '\\t', index = False)\n",
    "valset.to_csv(save_path + \"val.tsv\", sep = '\\t', index = False)\n",
    "testset.to_csv(save_path + \"test.tsv\", sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta Data\n",
    "\n",
    "See fields description [here](https://nijianmo.github.io/amazon/index.html)\n",
    "\n",
    "15023058 lines\n",
    "\n",
    "Fields: 'category', 'tech1', 'description', 'fit', 'title', 'also_buy', 'image', 'tech2', 'brand', 'feature', 'rank', 'also_view', 'details', 'main_cat', 'similar_item', 'date', 'price', 'asin'\n",
    "\n",
    "Selected fields: \"asin\", \"category\", \"price\", \"brand\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_fields = [\"asin\", \"category\", \"price\", \"also_buy\", \"also_view\", \"brand\"]\n",
    "selected_fields = [\"asin\", \"category\", \"price\", \"brand\"]\n",
    "# import numpy as np\n",
    "\n",
    "# def price_to_id(price):\n",
    "#     if price == '':\n",
    "#         return 0\n",
    "#     p = price.strip().replace('$','').split('.')\n",
    "#     l,v = len(p[0]), int(p[0][0])\n",
    "# #     return (l-1) * 3 + (0 if v<3 else 1 if v < 6 else 2) + 1\n",
    "#     return (l-1) * 10 + v + 1\n",
    "\n",
    "# def clean(textline):\n",
    "#     return textline.replace(',','_').replace(' ','').replace('&','_').replace('\\t','')\n",
    "\n",
    "# with open(data_path + \"meta/filtered_meta.csv\", 'w') as fout:\n",
    "#     fout.write(\"ItemID\\tCategory\\tMin_Price\\tMax_Price\\tAlso_Buy\\tAlso_View\\tBrand\\n\")\n",
    "#     with open(data_path + \"meta/All_Amazon_Meta.json\", 'r') as fin:\n",
    "#         for i,line in enumerate(fin):\n",
    "#             if i % 100000 == 0:\n",
    "#                 print(f\"#line: {i}\", end = '\\r')\n",
    "#             info = eval(line)\n",
    "#             fout.write(info['asin'] + \"\\t\") # ItemID\n",
    "#             fout.write(\",\".join([clean(c) for c in info['category'] \\\n",
    "#                                  if len(c) < 30]) + \"\\t\") # Category\n",
    "#             try:\n",
    "#                 if len(info['price']) > 20:\n",
    "#                     fout.write(\"0\\t0\\t\")\n",
    "#                 else:\n",
    "#                     price = info['price'].split(\"-\") # Min_Price and Max_Price\n",
    "#                     if len(price) == 2:\n",
    "#                         fout.write(f\"{price_to_id(price[0])}\\t{price_to_id(price[1])}\\t\")\n",
    "#                     else:\n",
    "#                         pidx = price_to_id(price[0])\n",
    "#                         fout.write(f\"{pidx}\\t{pidx}\\t\")\n",
    "#             except:\n",
    "#                 fout.write(\"0\\t0\\t\")\n",
    "#             fout.write(\",\".join(info['also_buy']) + \"\\t\")\n",
    "#             fout.write(\",\".join(info['also_view']) + \"\\t\")\n",
    "#             fout.write(clean(info['brand'][:30]) + \"\\n\")\n",
    "#     print(f\"#line: {i}\", end = '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Min_Price</th>\n",
       "      <th>Max_Price</th>\n",
       "      <th>Also_Buy</th>\n",
       "      <th>Also_View</th>\n",
       "      <th>Brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6305121869</td>\n",
       "      <td>Clothing_Shoes_Jewelry,Women,Clothing,Tops_Tee...</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ninasill_Blouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6318708057</td>\n",
       "      <td>Clothing_Shoes_Jewelry,Traditional_CulturalWea...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coolred-Women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6342506256</td>\n",
       "      <td>Clothing_Shoes_Jewelry,Men,Clothing,Shorts,Car...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B07CRJ95M7,B008AHISU4,B07B8F98W2,B07DD98Q7R,B0...</td>\n",
       "      <td>Gaok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemID                                           Category  Min_Price  \\\n",
       "0  6305121869  Clothing_Shoes_Jewelry,Women,Clothing,Tops_Tee...         10   \n",
       "1  6318708057  Clothing_Shoes_Jewelry,Traditional_CulturalWea...         12   \n",
       "2  6342506256  Clothing_Shoes_Jewelry,Men,Clothing,Shorts,Car...         13   \n",
       "\n",
       "   Max_Price  Also_Buy                                          Also_View  \\\n",
       "0         12       NaN                                                NaN   \n",
       "1         12       NaN                                                NaN   \n",
       "2         13       NaN  B07CRJ95M7,B008AHISU4,B07B8F98W2,B07DD98Q7R,B0...   \n",
       "\n",
       "             Brand  \n",
       "0  Ninasill_Blouse  \n",
       "1    Coolred-Women  \n",
       "2             Gaok  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(data_path + \"meta/filtered_meta.csv\", sep = '\\t', nrows = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20026\n"
     ]
    }
   ],
   "source": [
    "items = {iid: False for iid in multicore_data['ItemID'].unique()}\n",
    "print(len(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8225386it [00:13, 603302.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item meta info of items in data set:\n",
      "Found: 20026\n",
      "Missing: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "item_meta = {}\n",
    "with open(data_path + \"meta/filtered_meta.csv\", 'r') as fin:\n",
    "    fin.readline()\n",
    "    for i,line in tqdm(enumerate(fin)):\n",
    "        meta_info = line.strip().split(\"\\t\")\n",
    "        item_id = meta_info[0]\n",
    "        if item_id in items:\n",
    "            item_meta[item_id] = meta_info\n",
    "            del items[item_id]\n",
    "            if len(items) == 0:\n",
    "                break\n",
    "print(\"Item meta info of items in data set:\")\n",
    "print(f\"Found: {len(item_meta)}\")\n",
    "print(f\"Missing: {len(items)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Category</th>\n",
       "      <th>MinPrice</th>\n",
       "      <th>MaxPrice</th>\n",
       "      <th>Brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0789743035</td>\n",
       "      <td>Electronics,Computers_amp;Accessories,Computer...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VisitAmazon'sJohnRayPage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0972683275</td>\n",
       "      <td>Electronics,Accessories_amp;Supplies,Audio_amp...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>VideoSecu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106171327X</td>\n",
       "      <td>Electronics,Computers_amp;Accessories,MemoryCa...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>SanDisk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemID                                           Category MinPrice  \\\n",
       "0  0789743035  Electronics,Computers_amp;Accessories,Computer...        0   \n",
       "1  0972683275  Electronics,Accessories_amp;Supplies,Audio_amp...       14   \n",
       "2  106171327X  Electronics,Computers_amp;Accessories,MemoryCa...       12   \n",
       "\n",
       "  MaxPrice                     Brand  \n",
       "0        0  VisitAmazon'sJohnRayPage  \n",
       "1       14                 VideoSecu  \n",
       "2       12                   SanDisk  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "item_meta_df = pd.DataFrame.from_dict(item_meta, orient = \"index\", columns = [\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"AlsoBuy\", \"AlsoView\", \"Brand\"])\n",
    "item_meta_df = item_meta_df[[\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"Brand\"]]\n",
    "item_meta_df = item_meta_df.reset_index(drop = True)\n",
    "# item_meta_df = pd.DataFrame.from_dict(item_meta, orient = \"index\", columns = [\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"Brand\"])\n",
    "# item_meta_df.insert(0, 'ItemID', item_meta_df.index)\n",
    "item_meta_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "from utils import setup_path\n",
    "save_path = target_path + \"meta_data/item.meta\"\n",
    "setup_path(save_path, is_dir = False)\n",
    "item_meta_df.to_csv(save_path, sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "from data.preprocess import build_vocab\n",
    "from utils import setup_path\n",
    "save_path = target_path + \"meta_data/item_fields.vocab\"\n",
    "setup_path(save_path, is_dir = False)\n",
    "build_vocab(item_meta_df, save_path, [\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"Brand\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# item_fields_meta = pd.DataFrame({\"field_name\": [\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"AlsoBuy\", \"AlsoView\", \"Brand\"], \n",
    "#                                  \"field_type\": [\"nominal\", \"nominal\", \"ordinal\", \"ordinal\", \"nominal\", \"nominal\", \"nominal\"], \n",
    "#                                  \"value_type\": [\"int\", \"str\", \"int\", \"int\", \"int\", \"int\", \"str\"], \n",
    "#                                  \"field_enc\": [\"v2id\", \"v2onehot\", \"v2id\", \"v2id\", \"v2multid\", \"v2multid\", \"v2id\"], \n",
    "#                                  \"vocab_key\": [\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"ItemID\", \"ItemID\", \"Brand\"]})\n",
    "item_fields_meta = pd.DataFrame({\"field_name\": [\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"Brand\"], \n",
    "                                 \"field_type\": [\"nominal\", \"nominal\", \"ordinal\", \"ordinal\", \"nominal\"], \n",
    "                                 \"value_type\": [\"str\", \"str\", \"int\", \"int\", \"str\"], \n",
    "                                 \"field_enc\": [\"v2id\", \"v2onehot\", \"v2id\", \"v2id\", \"v2id\"], \n",
    "                                 \"vocab_key\": [\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"Brand\"]})\n",
    "item_fields_meta.to_csv(target_path + \"meta_data/item_fields.meta\", \n",
    "                        sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A100UD67AHFODS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A100WO06OQR8BQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1013Q9SD2KIE1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           UserID\n",
       "0  A100UD67AHFODS\n",
       "1  A100WO06OQR8BQ\n",
       "2  A1013Q9SD2KIE1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = {uid: uid for uid in multicore_data['UserID'].unique()}\n",
    "user_meta_df = pd.DataFrame.from_dict(users, orient = \"index\", columns = [\"UserID\"])\n",
    "user_meta_df = user_meta_df.reset_index(drop = True)\n",
    "user_meta_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "from utils import setup_path\n",
    "save_path = target_path + \"meta_data/user.meta\"\n",
    "setup_path(save_path, is_dir = False)\n",
    "user_meta_df.to_csv(save_path, sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "from data.preprocess import build_vocab\n",
    "from utils import setup_path\n",
    "save_path = target_path + \"meta_data/user_fields.vocab\"\n",
    "setup_path(save_path, is_dir = False)\n",
    "build_vocab(user_meta_df, save_path, [\"UserID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "user_fields_meta = pd.DataFrame({\"field_name\": [\"UserID\"], \n",
    "                          \"field_type\": [\"nominal\"], \n",
    "                          \"value_type\": [\"str\"], \n",
    "                          \"field_enc\": [\"v2id\"], \n",
    "                          \"vocab_key\": [\"UserID\"]})\n",
    "user_fields_meta.to_csv(target_path + \"meta_data/user_fields.meta\", sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BMRL",
   "language": "python",
   "name": "bmrl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
