{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Steps\n",
    "\n",
    "* Build vocab files for user and item, textline format: field  value  idx\n",
    "* Filter multicore rating data\n",
    "* Holdout train-val-test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "\n",
    "DATA_ROOT = \"/home/sl1471/public/\"\n",
    "PROCESSED_DATA_ROOT = \"/home/sl1471/workspace/experiments/\"\n",
    "data_path = DATA_ROOT + \"amazon_rating_only/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data file name, main_cat field in meta\n",
    "# domain = [\"Books\", \"Books\", 50, 50]\n",
    "# domain = [\"Clothing_Shoes_and_Jewelry\", \"Clothing_Shoes_Jewelry\", 25, 5]\n",
    "# domain = [\"Home_and_Kitchen\", \"Home_and_Kitchen\", 25, 5]\n",
    "domain = [\"Electronics\", \"Electronics\", 30, 5]\n",
    "# domain = [\"Sports_and_Outdoors\", \"Sports\", 10, 5]\n",
    "# domain = [\"Movies_and_TV\", \"Movies_and_TV\", 30, 10]\n",
    "# domain = [\"Video_Games\", \"Video_Games\", 15,  5]\n",
    "\n",
    "\n",
    "target_path = PROCESSED_DATA_ROOT + \"amz_\" + domain[0] + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>Response</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0060009810</td>\n",
       "      <td>A1N070NS9CJQ2I</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1026864000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0060009810</td>\n",
       "      <td>A3P0KRKOBQK1KN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1025913600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060009810</td>\n",
       "      <td>A192HO2ICJ75VU</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1025654400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemID          UserID  Response   Timestamp\n",
       "0  0060009810  A1N070NS9CJQ2I       5.0  1026864000\n",
       "1  0060009810  A3P0KRKOBQK1KN       5.0  1025913600\n",
       "2  0060009810  A192HO2ICJ75VU       5.0  1025654400"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_table(data_path + domain[0] + \".csv\", sep=\",\", names = [\"ItemID\", \"UserID\", \"Response\", \"Timestamp\"])\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#user: 9838676\n",
      "#item: 756489\n",
      "sparsity: 0.9999971792589499\n"
     ]
    }
   ],
   "source": [
    "n_user, n_item = len(df.UserID.unique()), len(df.ItemID.unique())\n",
    "print(f\"#user: {n_user}\")\n",
    "print(f\"#item: {n_item}\")\n",
    "print(f\"sparsity: {1.0 - len(df) / (n_user * n_item)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-core is set to [5,100]\n",
      "Filtering (30,5)-core data\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20994353/20994353 [00:34<00:00, 611521.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 20144710\n",
      "Iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 849643/849643 [00:01<00:00, 501379.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 297216\n",
      "Iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 552427/552427 [00:00<00:00, 662498.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 159187\n",
      "Iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393240/393240 [00:00<00:00, 669477.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 45574\n",
      "Iteration 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 347666/347666 [00:00<00:00, 625140.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 22762\n",
      "Iteration 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324904/324904 [00:00<00:00, 695395.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 10307\n",
      "Iteration 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 314597/314597 [00:00<00:00, 622652.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 4622\n",
      "Iteration 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 309975/309975 [00:00<00:00, 564589.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 2445\n",
      "Iteration 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307530/307530 [00:00<00:00, 563904.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 982\n",
      "Iteration 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 306548/306548 [00:00<00:00, 591193.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 408\n",
      "Iteration 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 306140/306140 [00:00<00:00, 622085.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 350\n",
      "Iteration 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305790/305790 [00:00<00:00, 713670.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 181\n",
      "Iteration 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305609/305609 [00:00<00:00, 648776.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 103\n",
      "Iteration 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305506/305506 [00:00<00:00, 650880.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 134\n",
      "Iteration 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305372/305372 [00:00<00:00, 674131.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 93\n",
      "Iteration 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305279/305279 [00:00<00:00, 668284.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 53\n",
      "Iteration 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305226/305226 [00:00<00:00, 525748.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 58\n",
      "Iteration 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305168/305168 [00:00<00:00, 624659.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 47\n",
      "Iteration 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305121/305121 [00:00<00:00, 567724.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 26\n",
      "Iteration 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305095/305095 [00:00<00:00, 600341.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 17\n",
      "Iteration 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 305078/305078 [00:00<00:00, 687115.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 0\n",
      "Size change: 20994353 --> 305078\n"
     ]
    }
   ],
   "source": [
    "from data.preprocess import run_multicore, run_multicore_asymetric\n",
    "# multicore_data = run_multicore(df[[\"UserID\", \"ItemID\", \"Response\", \"Timestamp\"]], n_core = domain[2])\n",
    "multicore_data = run_multicore_asymetric(df[[\"UserID\", \"ItemID\", \"Response\", \"Timestamp\"]], n_core_user = domain[2], n_core_item = domain[3])\n",
    "# multicore_data = run_multicore_asymetric(multicore_data, n_core_user = 30, n_core_item = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#user: 6527\n",
      "#item: 20080\n",
      "#record: 305078\n",
      "sparsity: 0.9976722648245687\n"
     ]
    }
   ],
   "source": [
    "n_user, n_item = len(multicore_data.UserID.unique()), len(multicore_data.ItemID.unique())\n",
    "print(f\"#user: {n_user}\")\n",
    "print(f\"#item: {n_item}\")\n",
    "print(f\"#record: {len(multicore_data)}\")\n",
    "print(f\"sparsity: {1.0 - len(multicore_data) / (n_user * n_item)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20080\n"
     ]
    }
   ],
   "source": [
    "items = {iid: False for iid in multicore_data['ItemID'].unique()}\n",
    "print(len(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15138777it [00:28, 528966.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20060/20\n",
      "#missing item meta: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# pd.read_csv(data_path + \"meta/filtered_meta.csv\", sep = '\\t', nrows = 3)\n",
    "item_meta = {}\n",
    "with open(data_path + \"meta/filtered_meta.csv\", 'r') as fin:\n",
    "    fin.readline()\n",
    "    for i,line in tqdm(enumerate(fin)):\n",
    "        meta_info = line.strip().split(\"\\t\")\n",
    "        item_id = meta_info[0]\n",
    "        if item_id in items:\n",
    "            item_meta[item_id] = meta_info\n",
    "            del items[item_id]\n",
    "            if len(items) == 0:\n",
    "                break\n",
    "print(\"Item meta info of items in data set:\")\n",
    "print(f\"Found: {len(item_meta)}\")\n",
    "print(f\"Missing: {len(items)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-core is set to [5,100]\n",
      "Filtering (30,5)-core data\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 304717/304717 [00:00<00:00, 666371.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 362\n",
      "Iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 304355/304355 [00:00<00:00, 895454.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 117\n",
      "Iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 304238/304238 [00:00<00:00, 996410.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 135\n",
      "Iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 304103/304103 [00:00<00:00, 843322.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 13\n",
      "Iteration 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 304090/304090 [00:00<00:00, 682652.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed record: 0\n",
      "Size change: 304717 --> 304090\n"
     ]
    }
   ],
   "source": [
    "selected_rows = [True] * len(multicore_data)\n",
    "for i,iid in enumerate(multicore_data[\"ItemID\"]):\n",
    "    if iid in items:\n",
    "        selected_rows[i] = False\n",
    "multicore_data = multicore_data[selected_rows]\n",
    "multicore_data = run_multicore_asymetric(multicore_data, domain[2], domain[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#user: 6510\n",
      "#item: 20026\n",
      "#record: 304090\n",
      "sparsity: 0.9976674716110224\n"
     ]
    }
   ],
   "source": [
    "n_user, n_item = len(multicore_data.UserID.unique()), len(multicore_data.ItemID.unique())\n",
    "print(f\"#user: {n_user}\")\n",
    "print(f\"#item: {n_item}\")\n",
    "print(f\"#record: {len(multicore_data)}\")\n",
    "print(f\"sparsity: {1.0 - len(multicore_data) / (n_user * n_item)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Response</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13378</th>\n",
       "      <td>A100UD67AHFODS</td>\n",
       "      <td>B0001D3K8A</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1150588800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16818</th>\n",
       "      <td>A100UD67AHFODS</td>\n",
       "      <td>B0002SQ2P2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1150588800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36655</th>\n",
       "      <td>A100UD67AHFODS</td>\n",
       "      <td>B000U0S304</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1349568000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               UserID      ItemID  Response   Timestamp\n",
       "13378  A100UD67AHFODS  B0001D3K8A       5.0  1150588800\n",
       "16818  A100UD67AHFODS  B0002SQ2P2       5.0  1150588800\n",
       "36655  A100UD67AHFODS  B000U0S304       5.0  1349568000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multicore_data = multicore_data.sort_values(by=['UserID','Timestamp'])\n",
    "multicore_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build user history\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "304090it [00:00, 405038.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout user histories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6510/6510 [00:00<00:00, 7372.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move unseen ItemID from val to train\n",
      "0/27946, finish in 1136015176.8s.   \r",
      "Moving user data\n",
      "Before moving: Target DataFrame: 248198, Source Data Frame: 27946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315/315 [00:00<00:00, 3831.15it/s]\n",
      "100%|██████████| 6195/6195 [00:01<00:00, 4085.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#user moved: 315\n",
      "After moving: Target DataFrame: 250151, Source Data Frame: 25993\n",
      "Move unseen ItemID from test to train, this may also move users in val to train\n",
      "0/27946, finish in 915474987.0s.   \r",
      "Val --> Train\n",
      "Moving user data\n",
      "Before moving: Target DataFrame: 250151, Source Data Frame: 25993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 321/321 [00:00<00:00, 5796.16it/s]\n",
      "100%|██████████| 5931/5931 [00:01<00:00, 5699.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#user moved: 321\n",
      "After moving: Target DataFrame: 251667, Source Data Frame: 24477\n",
      "Test --> Train\n",
      "Moving user data\n",
      "Before moving: Target DataFrame: 251667, Source Data Frame: 27946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 321/321 [00:00<00:00, 3846.13it/s]\n",
      "100%|██████████| 6189/6189 [00:01<00:00, 4250.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#user moved: 321\n",
      "After moving: Target DataFrame: 253715, Source Data Frame: 25898\n"
     ]
    }
   ],
   "source": [
    "from utils import set_random_seed\n",
    "set_random_seed(9)\n",
    "from data.preprocess import holdout_data_sequential, recheck_exist\n",
    "trainset, valset, testset = holdout_data_sequential(multicore_data, holdout_type = \"warm\", ratio = [0.8,0.1,0.1])\n",
    "trainset = trainset.reset_index(drop = True)\n",
    "valset = valset.reset_index(drop = True)\n",
    "testset = testset.reset_index(drop = True)\n",
    "# recheck if there is any unseen item in val or test, if there is move corresponding user history into train\n",
    "trainset, valset, testset = recheck_exist(trainset, valset, testset, field_name = \"ItemID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error when creating \"\"\n",
      "dir \"/home\" existed\n",
      "dir \"/home/sl1471\" existed\n",
      "dir \"/home/sl1471/workspace\" existed\n",
      "dir \"/home/sl1471/workspace/experiments\" existed\n",
      "dir \"/home/sl1471/workspace/experiments/amz_Electronics\" existed\n",
      "dir \"/home/sl1471/workspace/experiments/amz_Electronics/tsv_data\" existed\n",
      "dir \"/home/sl1471/workspace/experiments/amz_Electronics/tsv_data/\" existed\n"
     ]
    }
   ],
   "source": [
    "from utils import setup_path\n",
    "save_path = target_path + \"tsv_data/\"\n",
    "setup_path(save_path, is_dir = True)\n",
    "trainset.to_csv(save_path + \"train.tsv\", sep = '\\t', index = False)\n",
    "valset.to_csv(save_path + \"val.tsv\", sep = '\\t', index = False)\n",
    "testset.to_csv(save_path + \"test.tsv\", sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6510, 5931, 6189)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset[\"UserID\"].unique()), len(valset[\"UserID\"].unique()), len(testset[\"UserID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20026, 9841, 9049)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset[\"ItemID\"].unique()), len(valset[\"ItemID\"].unique()), len(testset[\"ItemID\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta Data\n",
    "\n",
    "See fields description [here](https://nijianmo.github.io/amazon/index.html)\n",
    "\n",
    "15023058 lines\n",
    "\n",
    "Fields: 'category', 'tech1', 'description', 'fit', 'title', 'also_buy', 'image', 'tech2', 'brand', 'feature', 'rank', 'also_view', 'details', 'main_cat', 'similar_item', 'date', 'price', 'asin'\n",
    "\n",
    "Selected fields: \"asin\", \"category\", \"price\", \"brand\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_fields = [\"asin\", \"category\", \"price\", \"also_buy\", \"also_view\", \"brand\"]\n",
    "selected_fields = [\"asin\", \"category\", \"price\", \"brand\"]\n",
    "# import numpy as np\n",
    "\n",
    "# def price_to_id(price):\n",
    "#     if price == '':\n",
    "#         return 0\n",
    "#     p = price.strip().replace('$','').split('.')\n",
    "#     l,v = len(p[0]), int(p[0][0])\n",
    "# #     return (l-1) * 3 + (0 if v<3 else 1 if v < 6 else 2) + 1\n",
    "#     return (l-1) * 10 + v + 1\n",
    "\n",
    "# def clean(textline):\n",
    "#     return textline.replace(',','_').replace(' ','').replace('&','_').replace('\\t','')\n",
    "\n",
    "# with open(data_path + \"meta/filtered_meta.csv\", 'w') as fout:\n",
    "#     fout.write(\"ItemID\\tCategory\\tMin_Price\\tMax_Price\\tAlso_Buy\\tAlso_View\\tBrand\\n\")\n",
    "#     with open(data_path + \"meta/All_Amazon_Meta.json\", 'r') as fin:\n",
    "#         for i,line in enumerate(fin):\n",
    "#             if i % 100000 == 0:\n",
    "#                 print(f\"#line: {i}\", end = '\\r')\n",
    "#             info = eval(line)\n",
    "#             fout.write(info['asin'] + \"\\t\") # ItemID\n",
    "#             fout.write(\",\".join([clean(c) for c in info['category'] \\\n",
    "#                                  if len(c) < 30]) + \"\\t\") # Category\n",
    "#             try:\n",
    "#                 if len(info['price']) > 20:\n",
    "#                     fout.write(\"0\\t0\\t\")\n",
    "#                 else:\n",
    "#                     price = info['price'].split(\"-\") # Min_Price and Max_Price\n",
    "#                     if len(price) == 2:\n",
    "#                         fout.write(f\"{price_to_id(price[0])}\\t{price_to_id(price[1])}\\t\")\n",
    "#                     else:\n",
    "#                         pidx = price_to_id(price[0])\n",
    "#                         fout.write(f\"{pidx}\\t{pidx}\\t\")\n",
    "#             except:\n",
    "#                 fout.write(\"0\\t0\\t\")\n",
    "#             fout.write(\",\".join(info['also_buy']) + \"\\t\")\n",
    "#             fout.write(\",\".join(info['also_view']) + \"\\t\")\n",
    "#             fout.write(clean(info['brand'][:30]) + \"\\n\")\n",
    "#     print(f\"#line: {i}\", end = '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Min_Price</th>\n",
       "      <th>Max_Price</th>\n",
       "      <th>Also_Buy</th>\n",
       "      <th>Also_View</th>\n",
       "      <th>Brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6305121869</td>\n",
       "      <td>Clothing_Shoes_Jewelry,Women,Clothing,Tops_Tee...</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ninasill_Blouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6318708057</td>\n",
       "      <td>Clothing_Shoes_Jewelry,Traditional_CulturalWea...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coolred-Women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6342506256</td>\n",
       "      <td>Clothing_Shoes_Jewelry,Men,Clothing,Shorts,Car...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B07CRJ95M7,B008AHISU4,B07B8F98W2,B07DD98Q7R,B0...</td>\n",
       "      <td>Gaok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemID                                           Category  Min_Price  \\\n",
       "0  6305121869  Clothing_Shoes_Jewelry,Women,Clothing,Tops_Tee...         10   \n",
       "1  6318708057  Clothing_Shoes_Jewelry,Traditional_CulturalWea...         12   \n",
       "2  6342506256  Clothing_Shoes_Jewelry,Men,Clothing,Shorts,Car...         13   \n",
       "\n",
       "   Max_Price  Also_Buy                                          Also_View  \\\n",
       "0         12       NaN                                                NaN   \n",
       "1         12       NaN                                                NaN   \n",
       "2         13       NaN  B07CRJ95M7,B008AHISU4,B07B8F98W2,B07DD98Q7R,B0...   \n",
       "\n",
       "             Brand  \n",
       "0  Ninasill_Blouse  \n",
       "1    Coolred-Women  \n",
       "2             Gaok  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(data_path + \"meta/filtered_meta.csv\", sep = '\\t', nrows = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20026\n"
     ]
    }
   ],
   "source": [
    "items = {iid: False for iid in multicore_data['ItemID'].unique()}\n",
    "print(len(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8225386it [00:15, 533517.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item meta info of items in data set:\n",
      "Found: 20026\n",
      "Missing: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "item_meta = {}\n",
    "with open(data_path + \"meta/filtered_meta.csv\", 'r') as fin:\n",
    "    fin.readline()\n",
    "    for i,line in tqdm(enumerate(fin)):\n",
    "        meta_info = line.strip().split(\"\\t\")\n",
    "        item_id = meta_info[0]\n",
    "        if item_id in items:\n",
    "            item_meta[item_id] = meta_info\n",
    "            del items[item_id]\n",
    "            if len(items) == 0:\n",
    "                break\n",
    "print(\"Item meta info of items in data set:\")\n",
    "print(f\"Found: {len(item_meta)}\")\n",
    "print(f\"Missing: {len(items)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Category</th>\n",
       "      <th>MinPrice</th>\n",
       "      <th>MaxPrice</th>\n",
       "      <th>Brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0789743035</td>\n",
       "      <td>Electronics,Computers_amp;Accessories,Computer...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>VisitAmazon'sJohnRayPage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0972683275</td>\n",
       "      <td>Electronics,Accessories_amp;Supplies,Audio_amp...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>VideoSecu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106171327X</td>\n",
       "      <td>Electronics,Computers_amp;Accessories,MemoryCa...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>SanDisk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemID                                           Category MinPrice  \\\n",
       "0  0789743035  Electronics,Computers_amp;Accessories,Computer...        0   \n",
       "1  0972683275  Electronics,Accessories_amp;Supplies,Audio_amp...       14   \n",
       "2  106171327X  Electronics,Computers_amp;Accessories,MemoryCa...       12   \n",
       "\n",
       "  MaxPrice                     Brand  \n",
       "0        0  VisitAmazon'sJohnRayPage  \n",
       "1       14                 VideoSecu  \n",
       "2       12                   SanDisk  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "item_meta_df = pd.DataFrame.from_dict(item_meta, orient = \"index\", columns = [\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"AlsoBuy\", \"AlsoView\", \"Brand\"])\n",
    "item_meta_df = item_meta_df[[\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"Brand\"]]\n",
    "item_meta_df = item_meta_df.reset_index(drop = True)\n",
    "# item_meta_df = pd.DataFrame.from_dict(item_meta, orient = \"index\", columns = [\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"Brand\"])\n",
    "# item_meta_df.insert(0, 'ItemID', item_meta_df.index)\n",
    "item_meta_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error when creating \"\"\n",
      "dir \"/home\" existed\n",
      "dir \"/home/sl1471\" existed\n",
      "dir \"/home/sl1471/workspace\" existed\n",
      "dir \"/home/sl1471/workspace/experiments\" existed\n",
      "dir \"/home/sl1471/workspace/experiments/amz_Electronics\" existed\n",
      "dir \"/home/sl1471/workspace/experiments/amz_Electronics/meta_data\" existed\n"
     ]
    }
   ],
   "source": [
    "from utils import setup_path\n",
    "save_path = target_path + \"meta_data/item.meta\"\n",
    "setup_path(save_path, is_dir = False)\n",
    "item_meta_df.to_csv(save_path, sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error when creating \"\"\n",
      "dir \"/home\" existed\n",
      "dir \"/home/sl1471\" existed\n",
      "dir \"/home/sl1471/workspace\" existed\n",
      "dir \"/home/sl1471/workspace/experiments\" existed\n",
      "dir \"/home/sl1471/workspace/experiments/amz_Electronics\" existed\n",
      "dir \"/home/sl1471/workspace/experiments/amz_Electronics/meta_data\" existed\n",
      "Vocab file saved to: /home/sl1471/workspace/experiments/amz_Electronics/meta_data/item_fields.vocab\n"
     ]
    }
   ],
   "source": [
    "from data.preprocess import build_vocab\n",
    "from utils import setup_path\n",
    "save_path = target_path + \"meta_data/item_fields.vocab\"\n",
    "setup_path(save_path, is_dir = False)\n",
    "build_vocab(item_meta_df, save_path, [\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"Brand\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# item_fields_meta = pd.DataFrame({\"field_name\": [\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"AlsoBuy\", \"AlsoView\", \"Brand\"], \n",
    "#                                  \"field_type\": [\"nominal\", \"nominal\", \"ordinal\", \"ordinal\", \"nominal\", \"nominal\", \"nominal\"], \n",
    "#                                  \"value_type\": [\"int\", \"str\", \"int\", \"int\", \"int\", \"int\", \"str\"], \n",
    "#                                  \"field_enc\": [\"v2id\", \"v2onehot\", \"v2id\", \"v2id\", \"v2multid\", \"v2multid\", \"v2id\"], \n",
    "#                                  \"vocab_key\": [\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"ItemID\", \"ItemID\", \"Brand\"]})\n",
    "item_fields_meta = pd.DataFrame({\"field_name\": [\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"Brand\"], \n",
    "                                 \"field_type\": [\"nominal\", \"nominal\", \"ordinal\", \"ordinal\", \"nominal\"], \n",
    "                                 \"value_type\": [\"str\", \"str\", \"int\", \"int\", \"str\"], \n",
    "                                 \"field_enc\": [\"v2id\", \"v2onehot\", \"v2id\", \"v2id\", \"v2id\"], \n",
    "                                 \"vocab_key\": [\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"Brand\"]})\n",
    "item_fields_meta.to_csv(target_path + \"meta_data/item_fields.meta\", \n",
    "                        sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A100UD67AHFODS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A100WO06OQR8BQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1013Q9SD2KIE1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           UserID\n",
       "0  A100UD67AHFODS\n",
       "1  A100WO06OQR8BQ\n",
       "2  A1013Q9SD2KIE1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = {uid: uid for uid in multicore_data['UserID'].unique()}\n",
    "user_meta_df = pd.DataFrame.from_dict(users, orient = \"index\", columns = [\"UserID\"])\n",
    "user_meta_df = user_meta_df.reset_index(drop = True)\n",
    "user_meta_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error when creating \"\"\n",
      "dir \"/home\" existed\n",
      "dir \"/home/sl1471\" existed\n",
      "dir \"/home/sl1471/workspace\" existed\n",
      "dir \"/home/sl1471/workspace/experiments\" existed\n",
      "dir \"/home/sl1471/workspace/experiments/amz_Electronics\" existed\n",
      "dir \"/home/sl1471/workspace/experiments/amz_Electronics/meta_data\" existed\n"
     ]
    }
   ],
   "source": [
    "from utils import setup_path\n",
    "save_path = target_path + \"meta_data/user.meta\"\n",
    "setup_path(save_path, is_dir = False)\n",
    "user_meta_df.to_csv(save_path, sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error when creating \"\"\n",
      "dir \"/home\" existed\n",
      "dir \"/home/sl1471\" existed\n",
      "dir \"/home/sl1471/workspace\" existed\n",
      "dir \"/home/sl1471/workspace/experiments\" existed\n",
      "dir \"/home/sl1471/workspace/experiments/amz_Electronics\" existed\n",
      "dir \"/home/sl1471/workspace/experiments/amz_Electronics/meta_data\" existed\n",
      "Vocab file saved to: /home/sl1471/workspace/experiments/amz_Electronics/meta_data/user_fields.vocab\n"
     ]
    }
   ],
   "source": [
    "from data.preprocess import build_vocab\n",
    "from utils import setup_path\n",
    "save_path = target_path + \"meta_data/user_fields.vocab\"\n",
    "setup_path(save_path, is_dir = False)\n",
    "build_vocab(user_meta_df, save_path, [\"UserID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "user_fields_meta = pd.DataFrame({\"field_name\": [\"UserID\"], \n",
    "                          \"field_type\": [\"nominal\"], \n",
    "                          \"value_type\": [\"str\"], \n",
    "                          \"field_enc\": [\"v2id\"], \n",
    "                          \"vocab_key\": [\"UserID\"]})\n",
    "user_fields_meta.to_csv(target_path + \"meta_data/user_fields.meta\", sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BMRL",
   "language": "python",
   "name": "bmrl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
