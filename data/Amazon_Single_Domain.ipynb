{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Steps\n",
    "\n",
    "* Build vocab files for user and item, textline format: field  value  idx\n",
    "* Filter multicore rating data\n",
    "* Holdout train-val-test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "\n",
    "DATA_ROOT = \"/home/sl1471/public/\"\n",
    "PROCESSED_DATA_ROOT = \"/home/sl1471/workspace/experiments/\"\n",
    "data_path = DATA_ROOT + \"amazon_rating_only/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data file name, main_cat field in meta\n",
    "# domain = [\"Books\", \"Books\", 50, 50]\n",
    "# domain = [\"Clothing_Shoes_and_Jewelry\", \"Clothing_Shoes_Jewelry\", 25, 5]\n",
    "# domain = [\"Home_and_Kitchen\", \"Home_and_Kitchen\", 25, 5]\n",
    "# domain = [\"Electronics\", \"Electronics\", 24, 10]\n",
    "# domain = [\"Sports_and_Outdoors\", \"Sports\", 10, 5]\n",
    "# domain = [\"Movies_and_TV\", \"Movies_and_TV\", 30, 10]\n",
    "domain = [\"Video_Games\", \"Video_Games\", 15,  5]\n",
    "\n",
    "\n",
    "target_path = PROCESSED_DATA_ROOT + \"amz_\" + domain[0] + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>Response</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0439381673</td>\n",
       "      <td>A21ROB4YDOZA5P</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1402272000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0439381673</td>\n",
       "      <td>A3TNZ2Q5E7HTHD</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1399680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0439381673</td>\n",
       "      <td>A1OKRM3QFEATQO</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1391731200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemID          UserID  Response   Timestamp\n",
       "0  0439381673  A21ROB4YDOZA5P       1.0  1402272000\n",
       "1  0439381673  A3TNZ2Q5E7HTHD       3.0  1399680000\n",
       "2  0439381673  A1OKRM3QFEATQO       4.0  1391731200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_table(data_path + domain[0] + \".csv\", sep=\",\", names = [\"ItemID\", \"UserID\", \"Response\", \"Timestamp\"])\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#user: 1540618\n",
      "#item: 71982\n",
      "sparsity: 0.9999768672332068\n"
     ]
    }
   ],
   "source": [
    "n_user, n_item = len(df.UserID.unique()), len(df.ItemID.unique())\n",
    "print(f\"#user: {n_user}\")\n",
    "print(f\"#item: {n_item}\")\n",
    "print(f\"sparsity: {1.0 - len(df) / (n_user * n_item)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data.preprocess import run_multicore, run_multicore_asymetric\n",
    "# multicore_data = run_multicore(df[[\"UserID\", \"ItemID\", \"Response\", \"Timestamp\"]], n_core = domain[2])\n",
    "multicore_data = run_multicore_asymetric(df[[\"UserID\", \"ItemID\", \"Response\", \"Timestamp\"]], n_core_user = domain[2], n_core_item = domain[3])\n",
    "# multicore_data = run_multicore_asymetric(multicore_data, n_core_user = 30, n_core_item = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_user, n_item = len(multicore_data.UserID.unique()), len(multicore_data.ItemID.unique())\n",
    "print(f\"#user: {n_user}\")\n",
    "print(f\"#item: {n_item}\")\n",
    "print(f\"#record: {len(multicore_data)}\")\n",
    "print(f\"sparsity: {1.0 - len(multicore_data) / (n_user * n_item)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multicore_data = multicore_data.sort_values(by=['UserID','Timestamp'])\n",
    "multicore_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import set_random_seed\n",
    "set_random_seed(9)\n",
    "from data.preprocess import holdout_data_sequential, recheck_exist\n",
    "trainset, valset, testset = holdout_data_sequential(multicore_data, holdout_type = \"warm\", ratio = [0.8,0.1,0.1])\n",
    "trainset = trainset.reset_index(drop = True)\n",
    "valset = valset.reset_index(drop = True)\n",
    "testset = testset.reset_index(drop = True)\n",
    "# recheck if there is any unseen item in val or test, if there is move corresponding user history into train\n",
    "trainset, valset, testset = recheck_exist(trainset, valset, testset, field_name = \"ItemID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import setup_path\n",
    "save_path = target_path + \"tsv_data/\"\n",
    "setup_path(save_path, is_dir = True)\n",
    "trainset.to_csv(save_path + \"train.tsv\", sep = '\\t', index = False)\n",
    "valset.to_csv(save_path + \"val.tsv\", sep = '\\t', index = False)\n",
    "testset.to_csv(save_path + \"test.tsv\", sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainset[\"UserID\"].unique()), len(valset[\"UserID\"].unique()), len(testset[\"UserID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainset[\"ItemID\"].unique()), len(valset[\"ItemID\"].unique()), len(testset[\"ItemID\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta Data\n",
    "\n",
    "See fields description [here](https://nijianmo.github.io/amazon/index.html)\n",
    "\n",
    "15023058 lines\n",
    "\n",
    "Fields: 'category', 'tech1', 'description', 'fit', 'title', 'also_buy', 'image', 'tech2', 'brand', 'feature', 'rank', 'also_view', 'details', 'main_cat', 'similar_item', 'date', 'price', 'asin'\n",
    "\n",
    "Selected fields: \"asin\", \"category\", \"price\", \"brand\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_fields = [\"asin\", \"category\", \"price\", \"also_buy\", \"also_view\", \"brand\"]\n",
    "selected_fields = [\"asin\", \"category\", \"price\", \"brand\"]\n",
    "# import numpy as np\n",
    "\n",
    "# def price_to_id(price):\n",
    "#     if price == '':\n",
    "#         return 0\n",
    "#     p = price.strip().replace('$','').split('.')\n",
    "#     l,v = len(p[0]), int(p[0][0])\n",
    "# #     return (l-1) * 3 + (0 if v<3 else 1 if v < 6 else 2) + 1\n",
    "#     return (l-1) * 10 + v + 1\n",
    "\n",
    "# def clean(textline):\n",
    "#     return textline.replace(',','_').replace(' ','').replace('&','_').replace('\\t','')\n",
    "\n",
    "# with open(data_path + \"meta/filtered_meta.csv\", 'w') as fout:\n",
    "#     fout.write(\"ItemID\\tCategory\\tMin_Price\\tMax_Price\\tAlso_Buy\\tAlso_View\\tBrand\\n\")\n",
    "#     with open(data_path + \"meta/All_Amazon_Meta.json\", 'r') as fin:\n",
    "#         for i,line in enumerate(fin):\n",
    "#             if i % 100000 == 0:\n",
    "#                 print(f\"#line: {i}\", end = '\\r')\n",
    "#             info = eval(line)\n",
    "#             fout.write(info['asin'] + \"\\t\") # ItemID\n",
    "#             fout.write(\",\".join([clean(c) for c in info['category'] \\\n",
    "#                                  if len(c) < 30]) + \"\\t\") # Category\n",
    "#             try:\n",
    "#                 if len(info['price']) > 20:\n",
    "#                     fout.write(\"0\\t0\\t\")\n",
    "#                 else:\n",
    "#                     price = info['price'].split(\"-\") # Min_Price and Max_Price\n",
    "#                     if len(price) == 2:\n",
    "#                         fout.write(f\"{price_to_id(price[0])}\\t{price_to_id(price[1])}\\t\")\n",
    "#                     else:\n",
    "#                         pidx = price_to_id(price[0])\n",
    "#                         fout.write(f\"{pidx}\\t{pidx}\\t\")\n",
    "#             except:\n",
    "#                 fout.write(\"0\\t0\\t\")\n",
    "#             fout.write(\",\".join(info['also_buy']) + \"\\t\")\n",
    "#             fout.write(\",\".join(info['also_view']) + \"\\t\")\n",
    "#             fout.write(clean(info['brand'][:30]) + \"\\n\")\n",
    "#     print(f\"#line: {i}\", end = '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "pd.read_csv(data_path + \"meta/filtered_meta.csv\", sep = '\\t', nrows = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = {iid: False for iid in multicore_data['ItemID'].unique()}\n",
    "print(len(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_meta = {}\n",
    "with open(data_path + \"meta/filtered_meta.csv\", 'r') as fin:\n",
    "    fin.readline()\n",
    "    for i,line in tqdm(enumerate(fin)):\n",
    "        meta_info = line.strip().split(\"\\t\")\n",
    "        item_id = meta_info[0]\n",
    "        if item_id in items:\n",
    "            item_meta[item_id] = meta_info\n",
    "            del items[item_id]\n",
    "            if len(items) == 0:\n",
    "                break\n",
    "print(f\"{len(item_meta)}/{len(items)}\")\n",
    "print(f\"#missing item meta: {len(items)}\")\n",
    "for iid in items:\n",
    "    item_meta[iid] = [iid, domain[1], 0, 0, '', '', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "item_meta_df = pd.DataFrame.from_dict(item_meta, orient = \"index\", columns = [\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"AlsoBuy\", \"AlsoView\", \"Brand\"])\n",
    "item_meta_df = item_meta_df[[\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"Brand\"]]\n",
    "item_meta_df = item_meta_df.reset_index(drop = True)\n",
    "# item_meta_df = pd.DataFrame.from_dict(item_meta, orient = \"index\", columns = [\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"Brand\"])\n",
    "# item_meta_df.insert(0, 'ItemID', item_meta_df.index)\n",
    "item_meta_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import setup_path\n",
    "save_path = target_path + \"meta_data/item.meta\"\n",
    "setup_path(save_path, is_dir = False)\n",
    "item_meta_df.to_csv(save_path, sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.preprocess import build_vocab\n",
    "from utils import setup_path\n",
    "save_path = target_path + \"meta_data/item_fields.vocab\"\n",
    "setup_path(save_path, is_dir = False)\n",
    "build_vocab(item_meta_df, save_path, [\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"Brand\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# item_fields_meta = pd.DataFrame({\"field_name\": [\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"AlsoBuy\", \"AlsoView\", \"Brand\"], \n",
    "#                                  \"field_type\": [\"nominal\", \"nominal\", \"ordinal\", \"ordinal\", \"nominal\", \"nominal\", \"nominal\"], \n",
    "#                                  \"value_type\": [\"int\", \"str\", \"int\", \"int\", \"int\", \"int\", \"str\"], \n",
    "#                                  \"field_enc\": [\"v2id\", \"v2onehot\", \"v2id\", \"v2id\", \"v2multid\", \"v2multid\", \"v2id\"], \n",
    "#                                  \"vocab_key\": [\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"ItemID\", \"ItemID\", \"Brand\"]})\n",
    "item_fields_meta = pd.DataFrame({\"field_name\": [\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"Brand\"], \n",
    "                                 \"field_type\": [\"nominal\", \"nominal\", \"ordinal\", \"ordinal\", \"nominal\"], \n",
    "                                 \"value_type\": [\"str\", \"str\", \"int\", \"int\", \"str\"], \n",
    "                                 \"field_enc\": [\"v2id\", \"v2onehot\", \"v2id\", \"v2id\", \"v2id\"], \n",
    "                                 \"vocab_key\": [\"ItemID\", \"Category\", \"MinPrice\", \"MaxPrice\", \"Brand\"]})\n",
    "item_fields_meta.to_csv(target_path + \"meta_data/item_fields.meta\", \n",
    "                        sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = {uid: uid for uid in multicore_data['UserID'].unique()}\n",
    "user_meta_df = pd.DataFrame.from_dict(users, orient = \"index\", columns = [\"UserID\"])\n",
    "user_meta_df = user_meta_df.reset_index(drop = True)\n",
    "user_meta_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import setup_path\n",
    "save_path = target_path + \"meta_data/user.meta\"\n",
    "setup_path(save_path, is_dir = False)\n",
    "user_meta_df.to_csv(save_path, sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.preprocess import build_vocab\n",
    "from utils import setup_path\n",
    "save_path = target_path + \"meta_data/user_fields.vocab\"\n",
    "setup_path(save_path, is_dir = False)\n",
    "build_vocab(user_meta_df, save_path, [\"UserID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "user_fields_meta = pd.DataFrame({\"field_name\": [\"UserID\"], \n",
    "                          \"field_type\": [\"nominal\"], \n",
    "                          \"value_type\": [\"str\"], \n",
    "                          \"field_enc\": [\"v2id\"], \n",
    "                          \"vocab_key\": [\"UserID\"]})\n",
    "user_fields_meta.to_csv(target_path + \"meta_data/user_fields.meta\", sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BMRL",
   "language": "python",
   "name": "bmrl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
