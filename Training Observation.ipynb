{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Example Performance Uploads with Noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = [0.47355184638423353,0.4880126114596745,0.48197951076343787,0.4910955877995803,0.49148326528871633,0.4942378553333534,0.49584690352035904,0.4998314645835072,0.5052953918607438,0.5029510307609053]\n",
    "A = np.array([X,[0]*len(X)])\n",
    "sigma = 1.0\n",
    "personal_noise = (sigma * np.random.randn(2)).reshape((2,1))\n",
    "print(personal_noise)\n",
    "B = A + personal_noise\n",
    "C = B + 0.3 * np.random.randn(len(A),len(A[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "plt.figure(figsize = (16, 4))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(A.transpose())\n",
    "plt.ylim(-1.0,1.0)\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['G0(True group of user)','G1'])\n",
    "# plt.title('Original uploads')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(B.transpose())\n",
    "plt.ylim(-1.0,1.0)\n",
    "plt.xlabel('epoch')\n",
    "# plt.title('After adding personal noise')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(C.transpose())\n",
    "plt.ylim(-1.0,1.0)\n",
    "plt.xlabel('epoch')\n",
    "# plt.title('After adding epoch noise')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "def get_lower_bound(X, delta_1):\n",
    "    return X / (np.sqrt(2)*norm.ppf(0.5+delta_1))\n",
    "def get_upper_bound(X_actual, H, N, delta_2):\n",
    "    return H * X_actual * np.sqrt(N * delta_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "delta_list = [0.01*i for i in range(1,10)] + [0.1*i for i in range(1,5)]\n",
    "H = 0.001\n",
    "X_actual = 0.5\n",
    "delta_2 = 0.1\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "for p in range(7,12):\n",
    "    plt.plot(delta_list, [np.log(get_upper_bound(X_actual, H, 10**p, delta_2))] * len(delta_list), '--', label = 'N = $10^{' + str(p) + '}$')\n",
    "lbs = [np.log(get_lower_bound(1., delta_1)) for delta_1 in delta_list]\n",
    "plt.plot(delta_list, lbs, label = 'lower bound')\n",
    "plt.legend(title = r'$H=' + str(H) + ',\\delta_2=0.01}$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_actual = 0.5\n",
    "H = 0.001\n",
    "delta_1 = 0.1\n",
    "for p in range(7,12):\n",
    "    N = 10**p\n",
    "    ubs = [get_upper_bound(X_actual, H, N, delta_2) for delta_2 in delta_list]\n",
    "    plt.plot(delta_list, np.log(ubs), label = 'N = $10^{' + str(p) + '}$')\n",
    "plt.plot(delta_list, [np.log(get_lower_bound(1., 0.1))] * len(delta_list), ':', color = '#555555', label = r'lower bound ($\\delta_1$=' + str(delta_1) + ')')\n",
    "plt.legend(title = r'$H=' + str(H) + '$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Group Differences during Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.preprocess import ROOT\n",
    "group_feature = 'activity'\n",
    "best_setting = {'ml-1m': {'MF': [], \n",
    "                          'FedMF': [], \n",
    "                          'FairMF': [\n",
    "                              f'/logs/f2rec_train_and_eval_FairMF_lr0.00003_reg0.1_losspairwisebpr_lambda-0.7_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairMF_lr0.00003_reg0.1_losspairwisebpr_lambda-0.5_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairMF_lr0.00003_reg0.1_losspairwisebpr_lambda-0.3_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairMF_lr0.00003_reg0.1_losspairwisebpr_lambda-0.1_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairMF_lr0.00003_reg0.1_losspairwisebpr_lambda0.1_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairMF_lr0.00003_reg0.1_losspairwisebpr_lambda0.3_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairMF_lr0.00003_reg0.1_losspairwisebpr_lambda0.5_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairMF_lr0.00003_reg0.1_losspairwisebpr_lambda0.7_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairMF_lr0.00003_reg0.1_losspairwisebpr_lambda0.9_g{group_feature}.log'\n",
    "                          ],\n",
    "                          'F2MF': [\n",
    "#                               f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda-0.7_sigma0_g{group_feature}.log'\n",
    "#                               ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda-0.5_sigma0_g{group_feature}.log'\n",
    "#                               ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda-0.3_sigma0_g{group_feature}.log'\n",
    "#                               ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda-0.1_sigma0_g{group_feature}.log'\n",
    "#                               ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda0.1_sigma0_g{group_feature}.log'\n",
    "#                               ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda0.3_sigma0_g{group_feature}.log'\n",
    "#                               ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda0.5_sigma0_g{group_feature}.log'\n",
    "#                               ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda0.7_sigma0_g{group_feature}.log'\n",
    "#                               ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda0.9_sigma0_g{group_feature}.log'\n",
    "                              f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda-0.7_sigma0.01_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda-0.5_sigma0.01_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda-0.3_sigma0.01_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda-0.1_sigma0.01_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda0.1_sigma0.01_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda0.3_sigma0.01_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda0.5_sigma0.01_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda0.7_sigma0.01_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda0.9_sigma0.01_g{group_feature}.log'\n",
    "                          ]\n",
    "                         },\n",
    "               'amz_Movies_and_TV': {'MF': [], \n",
    "                          'FedMF': [], \n",
    "                          'FairMF': [\n",
    "                              f'/logs/f2rec_train_and_eval_FairMF_lr0.00001_reg1.0_losspairwisebpr_lambda-0.7_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairMF_lr0.00001_reg1.0_losspairwisebpr_lambda-0.5_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairMF_lr0.00001_reg1.0_losspairwisebpr_lambda-0.3_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairMF_lr0.00001_reg1.0_losspairwisebpr_lambda-0.1_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairMF_lr0.00001_reg1.0_losspairwisebpr_lambda0.1_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairMF_lr0.00001_reg1.0_losspairwisebpr_lambda0.3_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairMF_lr0.00001_reg1.0_losspairwisebpr_lambda0.5_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairMF_lr0.00001_reg1.0_losspairwisebpr_lambda0.7_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairMF_lr0.00001_reg1.0_losspairwisebpr_lambda0.9_g{group_feature}.log'\n",
    "                          ],\n",
    "                          'F2MF': [\n",
    "                              f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg1.0_losspairwisebpr_lambda-0.7_sigma0_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg1.0_losspairwisebpr_lambda-0.5_sigma0_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg1.0_losspairwisebpr_lambda-0.3_sigma0_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg1.0_losspairwisebpr_lambda-0.1_sigma0_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg1.0_losspairwisebpr_lambda0.1_sigma0_g{group_feature}_p.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg1.0_losspairwisebpr_lambda0.3_sigma0_g{group_feature}_p.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg1.0_losspairwisebpr_lambda0.5_sigma0_g{group_feature}_p.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg1.0_losspairwisebpr_lambda0.7_sigma0_g{group_feature}_p.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg1.0_losspairwisebpr_lambda0.9_sigma0_g{group_feature}.log'\n",
    "#                               f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg1.0_losspairwisebpr_lambda-0.7_sigma0.001_g{group_feature}.log'\n",
    "#                               ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg1.0_losspairwisebpr_lambda-0.5_sigma0.001_g{group_feature}.log'\n",
    "#                               ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg1.0_losspairwisebpr_lambda-0.3_sigma0.001_g{group_feature}.log'\n",
    "#                               ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg1.0_losspairwisebpr_lambda-0.1_sigma0.001_g{group_feature}.log'\n",
    "#                               ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg1.0_losspairwisebpr_lambda0.1_sigma0.001_g{group_feature}_p.log'\n",
    "#                               ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg1.0_losspairwisebpr_lambda0.3_sigma0.001_g{group_feature}_p.log'\n",
    "#                               ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg1.0_losspairwisebpr_lambda0.5_sigma0.001_g{group_feature}_p.log'\n",
    "#                               ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg1.0_losspairwisebpr_lambda0.7_sigma0.001_g{group_feature}_p.log'\n",
    "#                               ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg1.0_losspairwisebpr_lambda0.9_sigma0.001_g{group_feature}.log'\n",
    "                          ]\n",
    "                         }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import extract_args, extract_epochwise_result\n",
    "import numpy as np\n",
    "groups = []\n",
    "# data_key = 'ml-1m'\n",
    "data_key = 'amz_Movies_and_TV'\n",
    "# data_key = 'amz_Books'\n",
    "training_curves = {} # {fair_lambda: {group_feature: [values]}}\n",
    "D = {} # {fair_lambda: {group_feature: [values]}}\n",
    "for log_name in best_setting[data_key]['F2MF']:\n",
    "    log_file_path = ROOT + data_key + log_name\n",
    "    args = extract_args(log_file_path)\n",
    "    observation_result = extract_epochwise_result(log_file_path, 'Previous statistics:')\n",
    "    if len(groups) == 0:\n",
    "        groups = [G for G in observation_result[0]]\n",
    "    training_curves[args.fair_lambda] = {G: np.array([epoch_result[G] for epoch_result in observation_result])\n",
    "                                         for G in groups}\n",
    "    D_log = extract_epochwise_result(log_file_path, 'D:', next_line = False)\n",
    "    D[args.fair_lambda] = {G: np.array([epoch_result[G] for epoch_result in D_log])\n",
    "                                         for G in groups}\n",
    "# print(training_curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_differences = {} # {fair_lambda: [value]}\n",
    "for lbd, group_curves in training_curves.items():\n",
    "    L = len(group_curves[groups[0]])\n",
    "    diff_sum,diff_count = np.zeros(L),0.\n",
    "    for i,G0 in enumerate(groups):\n",
    "        curve0 = group_curves[G0]\n",
    "        for G1 in groups[i+1:]:\n",
    "            curve1 = group_curves[G1]\n",
    "            diff_sum += np.abs(curve1 - curve0)\n",
    "            diff_count += 1\n",
    "    group_differences[lbd] = diff_sum / diff_count\n",
    "print(group_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_stats = {f'lambda={lbd}': group_D for lbd, group_D in D.items()}\n",
    "# title = 'ML1M(activity)'\n",
    "# plot_stats[title] = group_differences\n",
    "# print(plot_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import plot_multiple_line\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "data_name = {\"ml-1m\": 'ML1M', 'amz_Movies_and_TV': 'Movies', 'amz_Books': 'Books', 'amz_Electronics': 'Electronics'}\n",
    "title = f'{data_name[data_key]}({group_feature})'\n",
    "plot_multiple_line({'': group_differences}, [''], ncol = 2,\n",
    "                   ylabel = '', xlabel = '', legend_title = '$\\lambda$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 18})\n",
    "title = 'ML1M(activity)'\n",
    "plot_stats = {f'lambda={lbd}': group_D for lbd, group_D in D.items()}\n",
    "plot_multiple_line(plot_stats, list(plot_stats.keys()), ncol = 2, row_height = 6,\n",
    "                   ylabel = 'Value of D', xlabel = '', legend_title = 'group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Dominance of Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.preprocess import ROOT\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "group_feature = 'activity'\n",
    "best_setting = {'ml-1m': {'F2MF': [\n",
    "                              f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda-0.7_sigma0_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda-0.5_sigma0_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda-0.3_sigma0_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda-0.1_sigma0_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda0.1_sigma0_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda0.3_sigma0_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda0.5_sigma0_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda0.7_sigma0_g{group_feature}.log'\n",
    "                              ,f'/logs/f2rec_train_and_eval_FairFedMF_lr0.003_reg0.1_losspairwisebpr_lambda0.9_sigma0_g{group_feature}.log'\n",
    "                          ]\n",
    "                         },\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import extract_args, extract_epochwise_result\n",
    "import numpy as np\n",
    "groups = ['active','inactive']\n",
    "data_key = 'ml-1m'\n",
    "sigma_curves = {} # {fair_sigma: {fair_lambda: [values]}}\n",
    "for sigma in [0.0001,0.001,0.01]:\n",
    "    aggregated_noise = {G:[np.random.randn() * sigma for i in range(100)] for G in groups}\n",
    "    training_curves = {} # {fair_lambda: {group_feature: [values]}}\n",
    "    for log_name in best_setting[data_key]['F2MF']:\n",
    "        log_file_path = ROOT + data_key + log_name\n",
    "        args = extract_args(log_file_path)\n",
    "        observation_result = extract_epochwise_result(log_file_path, 'Previous statistics:')\n",
    "        training_curves[args.fair_lambda] = {G: np.array([epoch_result[G] + aggregated_noise[G][i]\n",
    "                                                          for i,epoch_result in enumerate(observation_result)])\n",
    "                                             for G in groups}\n",
    "    group_differences = {} # {fair_lambda: [values]}\n",
    "    for lbd, group_curves in training_curves.items():\n",
    "        L = len(group_curves[groups[0]])\n",
    "        diff_sum,diff_count = np.zeros(L),0.\n",
    "        for i,G0 in enumerate(groups):\n",
    "            curve0 = group_curves[G0]\n",
    "            for G1 in groups[i+1:]:\n",
    "                curve1 = group_curves[G1]\n",
    "                diff_sum += np.abs(curve1 - curve0)\n",
    "                diff_count += 1\n",
    "        group_differences[lbd] = diff_sum / diff_count\n",
    "    sigma_curves[sigma] = group_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_multiple_line(stats, features, ncol = 2, row_height = 4, no_title = False,\n",
    "                       ylabel = 'y', xlabel = 'x', legend_title = '', legend_appear_at = 0):\n",
    "    '''\n",
    "    @input:\n",
    "    - stats: {field_name: {key: [values]}}\n",
    "    - features: [field_name]\n",
    "    - ncol: number of subplots in each row\n",
    "    '''\n",
    "    assert ncol > 0\n",
    "    N = len(features)\n",
    "    fig_height = 12 // ncol if len(features) == 1 else row_height*((N-1)//ncol+1)\n",
    "    plt.figure(figsize = (16, fig_height))\n",
    "    for i,field in enumerate(features):\n",
    "        plt.subplot((N-1)//ncol+1,ncol,i+1)\n",
    "        minY,maxY = float('inf'),float('-inf')\n",
    "        for key, value_list in stats[field].items():\n",
    "#             print(key, value_list)\n",
    "            X = np.arange(1,len(value_list)+1)\n",
    "            minY,maxY = min(minY,min(value_list)),max(maxY,max(value_list))\n",
    "            plt.plot(X,value_list,label = key)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xlabel(xlabel)\n",
    "        if not no_title:\n",
    "            plt.title(field)\n",
    "        scale = 1e-4 + maxY - minY\n",
    "        plt.ylim(minY - scale * 0.05, maxY + scale * 0.05)\n",
    "        if i == legend_appear_at:\n",
    "            plt.legend(title = legend_title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "data_name = {\"ml-1m\": 'ML1M'}\n",
    "plot_multiple_line(sigma_curves, list(sigma_curves.keys()), ncol = 3, no_title = True,\n",
    "                   ylabel = '', xlabel = '', legend_title = '$\\lambda$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BMRL",
   "language": "python",
   "name": "bmrl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
